{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import funcy as fy\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import usgoc.preprocessing.graph.wl2 as wl2\n",
    "import usgoc.datasets.unsafe_go as dataset\n",
    "import usgoc.models.gnn as gnn\n",
    "import usgoc.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dbg] Preprocessing CFG 100/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 200/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 300/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 400/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 500/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 600/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 700/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 800/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 900/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 1000/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 1100/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 1200/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 1300/1400 (mode=atomic_blocks).\n",
      "[dbg] Preprocessing CFG 1400/1400 (mode=atomic_blocks).\n"
     ]
    }
   ],
   "source": [
    "split_i = 0 # the evaluated split number (between 0-9)\n",
    "\n",
    "with utils.cache_env(use_cache=True):\n",
    "  ds = dataset.load_dataset()\n",
    "  splits = dataset.get_split_idxs(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import usgoc.datasets.unsafe_go as dataset\n",
    "\n",
    "limit_id = \"v127_d127_f127_p127_nlp\"\n",
    "mode = \"atomic_blocks\"\n",
    "in_enc = \"wl2\"\n",
    "batch_size_limit=1\n",
    "\n",
    "with utils.cache_env(use_cache=True):\n",
    "  dims, train_ds, val_ds, test_ds = dataset.get_encoded_dataset_slices(\n",
    "      ds, in_enc, splits, split_i, limit_id=limit_id, mode=mode,\n",
    "      batch_size_limit=batch_size_limit)\n",
    "  train_ds = train_ds.cache()\n",
    "  val_ds = val_ds.cache()\n",
    "  train_slice, val_slice, test_slice = dataset.get_dataset_slices(\n",
    "      ds, splits, split_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': <tf.Tensor: shape=(7, 1630), dtype=float32, numpy=\n",
       " array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       " 'ref_a': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([0, 1, 1, 0, 2, 3, 3, 2, 4, 5, 5, 4, 6, 0, 2, 4], dtype=int32)>,\n",
       " 'ref_b': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([6, 0, 1, 0, 6, 2, 3, 2, 6, 4, 5, 4, 6, 0, 2, 4], dtype=int32)>,\n",
       " 'backref': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 6, 6], dtype=int32)>,\n",
       " 'graph_idx': <tf.Tensor: shape=(7,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'n': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([4], dtype=int32)>,\n",
       " 'marked_idx': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([6], dtype=int32)>,\n",
       " 'graph_X': <tf.Tensor: shape=(1, 1028), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.        ,  0.        , ..., -3.2382812 ,\n",
       "         -0.14550781,  5.84375   ]], dtype=float32)>}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_ds)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = splits[0][\"model_selection\"][0][\"train\"][1]\n",
    "graphs = ds[0]\n",
    "g = graphs[splits[0][\"model_selection\"][0][\"train\"][1]]\n",
    "utils.draw_graph(g, layout=\"dot\")\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'var kindTypes = map[reflect.Kind]Type{\\n\\treflect.Bool:          TypeOf(true),\\n\\treflect.Uint8:         TypeOf(uint8(0)),\\n\\treflect.Int8:          TypeOf(int8(0)),\\n\\treflect.Uint16:        TypeOf(uint16(0)),\\n\\treflect.Int16:         TypeOf(int16(0)),\\n\\treflect.Uint32:        TypeOf(uint32(0)),\\n\\treflect.Int32:         TypeOf(int32(0)),\\n\\treflect.Uint64:        TypeOf(uint64(0)),\\n\\treflect.Int64:         TypeOf(int64(0)),\\n\\treflect.Uint:          TypeOf(uint(0)),\\n\\treflect.Int:           TypeOf(int(0)),\\n\\treflect.Float32:       TypeOf(float32(0)),\\n\\treflect.Float64:       TypeOf(float64(0)),\\n\\treflect.Uintptr:       TypeOf(uintptr(0)),\\n\\treflect.String:        TypeOf(\"\"),\\n\\treflect.UnsafePointer: TypeOf(unsafe.Pointer(nil)),\\n}'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = g.nodes(data=True)[35][\"code\"]\n",
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CodeGenTokenizer\n",
    "\n",
    "checkpoint = \"Salesforce/codegen-350M-multi\"\n",
    "tokenizer = CodeGenTokenizer.from_pretrained(checkpoint, cache_dir=\"/app/.cache\")\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block_snippets(g, snippets=None):\n",
    "  if snippets is None:\n",
    "    snippets = set()\n",
    "  for node, data in g.nodes(data=True):\n",
    "    if \"code\" in data:\n",
    "      snippets.add(data[\"code\"])\n",
    "  return snippets\n",
    "\n",
    "graphs = ds[0]\n",
    "snippets = {g.source_code for g in graphs}\n",
    "\n",
    "for g in graphs:\n",
    "  get_block_snippets(g, snippets)\n",
    "\n",
    "snippets = list(snippets)\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"/app/data/unsafe-go-dataset/snippets.json\", \"w\") as f:\n",
    "  json.dump(snippets, f)\n",
    "\n",
    "len(snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "with open(\"/app/data/unsafe-go-dataset/embs.pickle\", \"rb\") as f:\n",
    "  embs = pickle.load(f)\n",
    "  \n",
    "embs = [e.reshape((-1, 1024)).mean(axis=0) for e in embs]\n",
    "\n",
    "with open(\"/app/data/unsafe-go-dataset/snippets.json\", \"r\") as f:\n",
    "  snippets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = fy.zipdict(snippets, embs)\n",
    "\n",
    "with open(\"/app/data/unsafe-go-dataset/emb_dict.pickle\", \"wb\") as f:\n",
    "  pickle.dump(emb_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.667 ,  3.625 ,  7.082 , ..., -3.238 , -0.1455,  5.844 ],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dict = dataset.embed_code_snippets(graphs)\n",
    "\n",
    "emb_dict[code]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
