{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import funcy as fy\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import usgoc.preprocessing.graph.wl2 as wl2\n",
    "import usgoc.datasets.unsafe_go as dataset\n",
    "import usgoc.models.gnn as gnn\n",
    "import usgoc.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_i = 0 # the evaluated split number (between 0-9)\n",
    "in_enc = \"wl1\"\n",
    "\n",
    "with utils.cache_env(use_cache=True):\n",
    "  ds = dataset.load_dataset()\n",
    "  splits = dataset.get_split_idxs(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='Salesforce/codegen-350M-multi', vocab_size=50257, model_max_len=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import CodeGenTokenizer\n",
    "\n",
    "checkpoint = \"Salesforce/codegen-350M-multi\"\n",
    "tokenizer = CodeGenTokenizer.from_pretrained(checkpoint, cache_dir=\"/app/.cache\")\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8803"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_block_snippets(g, snippets=None):\n",
    "  if snippets is None:\n",
    "    snippets = set()\n",
    "  for node, data in g.nodes(data=True):\n",
    "    if \"code\" in data:\n",
    "      snippets.add(data[\"code\"])\n",
    "  return snippets\n",
    "\n",
    "graphs = ds[0]\n",
    "snippets = {g.source_code for g in graphs}\n",
    "\n",
    "for g in graphs:\n",
    "  get_block_snippets(g, snippets)\n",
    "\n",
    "snippets = list(snippets)\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"/app/data/unsafe-go-dataset/snippets.json\", \"w\") as f:\n",
    "  json.dump(snippets, f)\n",
    "\n",
    "len(snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "with open(\"/app/data/unsafe-go-dataset/embs.pickle\", \"rb\") as f:\n",
    "  embs = pickle.load(f)\n",
    "  \n",
    "embs = [e.reshape((-1, 1024)).mean(axis=0) for e in embs]\n",
    "\n",
    "with open(\"/app/data/unsafe-go-dataset/snippets.json\", \"r\") as f:\n",
    "  snippets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = fy.zipdict(snippets, embs)\n",
    "\n",
    "with open(\"/app/data/unsafe-go-dataset/emb_dict.pickle\", \"wb\") as f:\n",
    "  pickle.dump(emb_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/app/data/unsafe-go-dataset/emb_dict.pickle\", \"rb\") as f:\n",
    "  emb_dict = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
