{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import funcy as fy\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import usgoc.preprocessing.graph.wl2 as wl2\n",
    "import usgoc.datasets.unsafe_go as dataset\n",
    "import usgoc.models.gnn as gnn\n",
    "import usgoc.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_i = 0 # the evaluated split number (between 0-9)\n",
    "in_enc = \"wl1\"\n",
    "\n",
    "with utils.cache_env(use_cache=True):\n",
    "  ds = dataset.load_dataset()\n",
    "  splits = dataset.get_split_idxs(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='Salesforce/codegen-350M-multi', vocab_size=50257, model_max_len=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import CodeGenTokenizer\n",
    "\n",
    "checkpoint = \"Salesforce/codegen-350M-multi\"\n",
    "tokenizer = CodeGenTokenizer.from_pretrained(checkpoint, cache_dir=\"/app/.cache\")\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Salesforce/codegen-350M-multi were not used when initializing CodeGenModel: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing CodeGenModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CodeGenModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from transformers import CodeGenModel, CodeGenForCausalLM\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "max_memory_mapping = {0: \"3000MB\"}\n",
    "model = CodeGenModel.from_pretrained(\n",
    "  checkpoint,\n",
    "  device_map=\"auto\", load_in_8bit=True,\n",
    "  max_memory=max_memory_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = ds[0]\n",
    "codes = [g.source_code for g in graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"snippets.json\", \"w\") as f:\n",
    "  json.dump(codes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "embs = []\n",
    "for code_part in fy.partition(10, codes):\n",
    "  print(len(code_part[0]))\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  tokens = tokenizer(\n",
    "    code_part, return_tensors=\"pt\", padding=True, truncation=True, \n",
    "    max_length=2048)\n",
    "  with torch.no_grad():\n",
    "    model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    6309 MB |    6309 MB |    6321 MB |   11744 KB |\n",
      "|       from large pool |    6309 MB |    6309 MB |    6320 MB |   11744 KB |\n",
      "|       from small pool |       0 MB |       0 MB |       0 MB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    6309 MB |    6309 MB |    6321 MB |   11744 KB |\n",
      "|       from large pool |    6309 MB |    6309 MB |    6320 MB |   11744 KB |\n",
      "|       from small pool |       0 MB |       0 MB |       0 MB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    6326 MB |    6326 MB |    6326 MB |       0 B  |\n",
      "|       from large pool |    6324 MB |    6324 MB |    6324 MB |       0 B  |\n",
      "|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   16628 KB |   22460 KB |  390622 KB |  373994 KB |\n",
      "|       from large pool |   14880 KB |   20480 KB |  388576 KB |  373696 KB |\n",
      "|       from small pool |    1748 KB |    2046 KB |    2046 KB |     298 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     188    |     189    |     190    |       2    |\n",
      "|       from large pool |     105    |     106    |     107    |       2    |\n",
      "|       from small pool |      83    |      83    |      83    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     188    |     189    |     190    |       2    |\n",
      "|       from large pool |     105    |     106    |     107    |       2    |\n",
      "|       from small pool |      83    |      83    |      83    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      34    |      34    |      34    |       0    |\n",
      "|       from large pool |      33    |      33    |      33    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       5    |       5    |      32    |      27    |\n",
      "|       from large pool |       4    |       4    |      31    |      27    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       1    |       1    |       1    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
