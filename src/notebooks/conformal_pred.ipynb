{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import usgoc.evaluation.evaluate as ee\n",
    "\n",
    "m, calibration_configs, h1, h2, h3, dims, train_ds, val_ds, test_ds = ee.evaluate(\n",
    "  \"GIN\",\n",
    "  convert_mode=\"atomic_blocks\", limit_id=\"v127_d127_f127_p127\",\n",
    "  fold=0, repeat=0, dry=True, \n",
    "  return_models=True, return_calibration_configs=True, return_size_histograms=True,\n",
    "  return_ds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from usgoc.postprocessing.calibration import platt_scaling\n",
    "\n",
    "preds1 = []\n",
    "preds2 = []\n",
    "trues1 = []\n",
    "trues2 = []\n",
    "\n",
    "for batch in test_ds:\n",
    "  pred1, pred2 = m(batch[0])\n",
    "  true1, true2 = batch[1]\n",
    "  preds1.append(pred1)\n",
    "  preds2.append(pred2)\n",
    "  trues1.append(true1)\n",
    "  trues2.append(true2)\n",
    "\n",
    "preds1 = np.concatenate(preds1)\n",
    "preds2 = np.concatenate(preds2)\n",
    "trues1 = np.concatenate(trues1)\n",
    "trues2 = np.concatenate(trues2)\n",
    "\n",
    "temp1 = platt_scaling(preds1, trues1)\n",
    "temp2 = platt_scaling(preds2, trues2)\n",
    "preds1 = preds1 / temp1\n",
    "preds2 = preds2 / temp2\n",
    "temp1, temp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import funcy as fy\n",
    "\n",
    "def compute_pred_cumsum(pred):\n",
    "  pred = tf.nn.softmax(pred).numpy()\n",
    "  # print(np.round(pred[ri:rj] * 1000))\n",
    "  pred_pi = np.argsort(pred)[:, ::-1]\n",
    "  pred_sorted = np.take_along_axis(pred, pred_pi, axis=1)\n",
    "  pred_cumsum = np.cumsum(pred_sorted, -1)\n",
    "  return pred_sorted, pred_cumsum, pred_pi\n",
    "\n",
    "ri, rj = 5, 10\n",
    "\n",
    "def adaptive_calibration_scores(pred, true):\n",
    "  pred_sorted, pred_cumsum, pred_pi = compute_pred_cumsum(pred)\n",
    "  pred_pi_inv = np.argsort(pred_pi)\n",
    "  # print(pred_pi_inv[ri:rj])\n",
    "  # print(np.round(pred_cumsum[ri:rj] * 1000))\n",
    "  true_cumsumidx = np.take_along_axis(\n",
    "    pred_pi_inv, np.expand_dims(true, 1), axis=1)\n",
    "  U = np.random.random_sample((pred_sorted.shape[0], 1))\n",
    "  pred_cumsum = np.pad(pred_cumsum, ((0, 0), (1, 0)), \"constant\")\n",
    "  # print(true[ri:rj])\n",
    "  scores = np.take_along_axis(pred_cumsum, true_cumsumidx, axis=1)\n",
    "  scores += np.take_along_axis(pred_sorted, true_cumsumidx, axis=1) * U\n",
    "  scores = np.squeeze(scores)\n",
    "  # print(np.round(scores[ri:rj] * 1000))\n",
    "  return scores\n",
    "\n",
    "scores1 = adaptive_calibration_scores(preds1, trues1)\n",
    "scores2 = adaptive_calibration_scores(preds2, trues2)\n",
    "\n",
    "n = scores1.shape[0]\n",
    "\n",
    "def conformal_sets(pred, qhat):\n",
    "  _, pred_cumsum, pred_pi = compute_pred_cumsum(pred)\n",
    "  sizes = np.argmax(pred_cumsum > qhat, axis=1)\n",
    "  pred_sets = [pred_pi[i][:(sizes[i] + 1)] for i in range(sizes.shape[0])]\n",
    "  # for i in range(sizes.shape[0]):\n",
    "  #   if len(pred_sets[i]) == 11:\n",
    "  #     print(\"zero info:\", pred[i], np.round(tf.nn.softmax(pred[i]).numpy() * 1000) / 10, qhat)\n",
    "  return pred_sets\n",
    "\n",
    "test_pred1, test_pred2 = m.predict(test_ds)\n",
    "test_pred1 = test_pred1 / temp1\n",
    "test_pred2 = test_pred2 / temp2\n",
    "test_true1, test_true2 = list(test_ds)[0][1]\n",
    "test_eval = m.evaluate(test_ds, return_dict=True)\n",
    "\n",
    "def get_test_sets(alpha):\n",
    "  q = np.ceil((n + 1) * (1 - alpha)) / n\n",
    "  qhat1 = np.quantile(scores1, q, method=\"higher\")\n",
    "  qhat2 = np.quantile(scores2, q, method=\"higher\")\n",
    "  print()\n",
    "  print(\"q\", q, \", qhat1\", qhat1, \", qhat2\", qhat2)\n",
    "  \n",
    "  test_set1 = conformal_sets(test_pred1, qhat1)\n",
    "  test_set2 = conformal_sets(test_pred2, qhat2)\n",
    "  ms1 = fy.ljuxt(np.min, np.mean, np.std, np.median, np.max)(fy.lmap(len, test_set1))\n",
    "  ms2 = fy.ljuxt(np.min, np.mean, np.std, np.median, np.max)(fy.lmap(len, test_set2))\n",
    "\n",
    "  # acc1 = np.mean((tf.argmax(test_pred1, -1).numpy() == test_true1).astype(np.int32))\n",
    "  setacc1 = np.mean([test_true1[i] in test_set1[i] for i in range(len(test_set1))])\n",
    "  setacc2 = np.mean([test_true2[i] in test_set2[i] for i in range(len(test_set2))])\n",
    "  combacc = np.mean([\n",
    "    test_true1[i] in test_set1[i] and test_true2[i] in test_set2[i]\n",
    "    for i in range(len(test_set1))\n",
    "  ])\n",
    "\n",
    "  print(ms1, test_eval[\"label1_accuracy\"], setacc1)\n",
    "  print(ms2, test_eval[\"label2_accuracy\"], setacc2)\n",
    "  print(test_eval[\"accuracy\"], combacc)\n",
    "  # print([(s, t) for s, t in zip(test_set2, test_true2.numpy()) if len(s) > 1])\n",
    "  return test_set1, test_set2, setacc1, setacc2, ms1, ms2, combacc\n",
    "\n",
    "\n",
    "alphas = [0.03, 0.05, 0.07, 0.1, 0.2, 0.5]\n",
    "# alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "res = [get_test_sets(a) for a in alphas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_set_hist(a, test_set1, test_set2, setacc1, setacc2, ms1, ms2, combacc):\n",
    "  combacc_diff = combacc - test_eval[\"accuracy\"]\n",
    "  print(f\"alpha = {a}, combacc = {combacc*100:.2f}% (+{combacc_diff*100:.2f}%)\")\n",
    "  setacc1 *= 100\n",
    "  setacc2 *= 100\n",
    "  true_acc1 = test_eval[\"label1_accuracy\"] * 100\n",
    "  true_acc2 = test_eval[\"label2_accuracy\"] * 100\n",
    "  size1a = ms1[1]\n",
    "  size2a = ms2[1]\n",
    "  size1m = ms1[3]\n",
    "  size2m = ms2[3]\n",
    "  setacc1_diff = setacc1 - true_acc1\n",
    "  setacc2_diff = setacc2 - true_acc2\n",
    "  bins = 1 + np.arange(11)\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "  fig.set_size_inches(6, 2)\n",
    "  sizes1 = fy.lmap(len, test_set1)\n",
    "  sizes2 = fy.lmap(len, test_set2)\n",
    "  hm1 = np.max(np.unique(sizes1, return_counts=True)[1])\n",
    "  hm2 = np.max(np.unique(sizes2, return_counts=True)[1])\n",
    "  \n",
    "  ax1.set_title(f\"L1: {size1a:.2f}, {setacc1:.2f} (+{setacc1_diff:.2f})\")\n",
    "  ax1.set_xticks(bins)\n",
    "  ax1.hist(sizes1, bins=bins)\n",
    "  ax1.vlines(size1a, 0, hm1, colors=\"red\")\n",
    "  ax1.vlines(size1m, 0, hm1, colors=\"orange\")\n",
    "  \n",
    "  ax2.set_xticks(bins)\n",
    "  ax2.set_title(f\"L2: {size2a:.2f}, {setacc2:.2f} (+{setacc2_diff:.2f})\")\n",
    "  ax2.hist(sizes2, bins=bins)\n",
    "  ax2.vlines(size2a, 0, hm2, colors=\"red\")\n",
    "  ax2.vlines(size2m, 0, hm2, colors=\"orange\")\n",
    "  \n",
    "  plt.show()\n",
    "\n",
    "for a, r in zip(alphas, res): \n",
    "  plot_set_hist(a, *r)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
